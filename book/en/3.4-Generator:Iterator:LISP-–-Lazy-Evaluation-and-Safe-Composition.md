## 3.4 Generator:Iterator:LISP – Lazy Evaluation and Safe Composition

In this chapter, we want to extend the viewpoint that **Generator:Iterator:LISP** can fully replace each other by implementing higher-order functions like `find`, `every`, and `some` solely through combinations of list processing functions. We’ll also delve into how function composition, safe value access, dealing with absent values, and language-level proposals address these topics.

### The `find` Function Signature

`map` and `filter` are examples of functions that produce a lazy iterator (a transform stage) so list processing can continue. By contrast, `find` is a “result-producing” function that evaluates a lazy iterator. It traverses an iterable, checking each element with `f`, and returns the first element for which `f` returns `true`. If no element satisfies the condition, it returns `undefined`.

Below is a partial representation of that behavior in the `find` function’s signature:

##### [Code 3-38] The TypeScript `find` Function Signature

```typescript
type Find = <A>(f: (a: A) => boolean, iterable: Iterable<A>) => A | undefined;
```

This signature indicates that `find` takes `(a: A) => boolean` (a function from `A` to `boolean`) and an `Iterable<A>`, returning either an `A`-type value or `undefined`. As mentioned before, being familiar with reading such function signatures will be very helpful in functional programming.

Now, to expand our perspective on “functions of type `find`,” let’s look at Haskell’s `find` function signature:

##### [Code 3-39] Haskell’s `find` Function Signature

```haskell
find :: (a -> Bool) -> [a] -> Maybe a
```

This signature means `find` takes `(a -> Bool)` and a list `[a]`, returning a `Maybe a`. `(a -> Bool)` is a function from `a` to `Bool`. Here, `a` is a generic type, and the signature that expresses such generic types concisely is elegant. Also, thanks to Haskell's default currying, notation like function overloading for different argument counts is unnecessary, making Haskell's signatures even more concise.

And the final return value, `Maybe a`, refers to `a` type that returns `Just a` when there is a first element satisfying the search condition, and `Nothing` when there isn't. In Haskell, for safe function composition situations similar to `A | undefined` in languages with TypeScript-like styles are handled with values of the `Maybe` type.

### `find` in Haskell and Safe Composition

##### [Code 3-40] An Example of Using `find` in Haskell
```haskell
import Data.Maybe (fromMaybe)
import Data.List (find)

main :: IO ()
main = do
    let result = fromMaybe 0 (find even [1, 3, 5])
    print result  -- Output: 0
```

This code is a simple example of using `find` in Haskell:

1. `main` is Haskell’s program entry point. `main` has type `IO ()`, which allows I/O operations.
2. `fromMaybe` takes two arguments. The first argument passed is 0, and by currying, it receives another argument. The value evaluated inside parentheses is passed as the second argument.
3. `find` also evaluates by taking `even` (a function of type `(a -> Bool)` that checks if a number is even) as the first argument, and `[1, 3, 5]` as the second argument.
4. The result of `find even [1, 3, 5]` is of type `Maybe`, returning `Nothing` because there are no even numbers in the list.
5. The `fromMaybe` function returns the default value `0` when it receives `Nothing`.
6. The `print` function outputs the `result` value.

This example demonstrates how to use the `find` function and `Maybe` type to find elements in a list that satisfy a condition and handle them safely. The `find` function takes a function of type `(a -> Bool)` and a list of type `[a]` to return a value of type `Maybe a`, and the `fromMaybe` function is useful for handling `Maybe` values by providing a default value.

Programming languages offer different solutions for handling optional situations like empty collection processing in `reduce` or potential absence of values in `find`. For example, Haskell clearly expresses these situations with declarative types and values, while TypeScript offers solutions through operators like `?.`, `!`, and `??`. By comparing these approaches across various languages, we can understand the solutions proposed by our primary language from a broader and deeper perspective.


### Rethinking Lazy Evaluation and List Processing via `find`

Returning to TypeScript, let’s build a `find` function that follows the iterable protocol.

##### [Code 3-41] The Imperative `find`

```typescript
function find<A>(f: (a: A) => boolean, iterable: Iterable<A>): A | undefined {
  const iterator = iterable[Symbol.iterator]();
  while (true) {
    const { value, done } = iterator.next();
    if (done) break;
    if (f(value)) return value;
  }
  return undefined;
}

const result = find(a => a > 2, [1, 2, 3, 4]);
console.log(result);
// 3
```

The `find` function traverses a given `iterable` and returns the first element that satisfies the predicate`f`. if no such element is found, it returns `undefined`. In TypeScript, you can omit return `undefined;` because a function that doesn't explicitly return a value implicitly returns `undefined`.

1. Create `iterator` object to prepare for iteration over the `iterable`.
2. It enters an infinite loop using `while (true)`, calling the `iterator.next()` method.
3. Destructure the result into `{ value, done }`.
4. If `done` is `true`, the iteration ends.
5. If `f(value)` is `true`, return `value`.
6. If no matching element is found by the end of the loop, it return `undefined`.
7. `result` ends up being 3.

We now want to reimplement `find` in a functional rather than an imperative style. Existing functions like `map`, `filter`, and `take` are either written imperatively using generators, or follow an object-oriented approach where one iterator invokes methods on another. If tail call optimization were available, these functions could also be implemented in a functional style. However, for `map`, `filter`, and `take`, the imperative approach often leads to code that is easier to understand.

In contrast, functions like `find`, `every`, and `some`—which return final results—can be written in a purely functional way by composing existing higher-order functions such as `map`, `filter`, and `reduce`. This approach improves both clarity and expressiveness.

Let’s compare the imperative version of `filter` with the functionally written version of find shown in [Code 3-41] to explore the differences between these styles.

##### [Code 3-42] Lazy `filter`

```typescript
function* filter<A>(f: (a: A) => boolean, iterable: Iterable<A>): IterableIterator<A> {
  const iterator = iterable[Symbol.iterator]();
  while (true) {
    const { value, done } = iterator.next();
    if (done) break;
    if (f(value)) yield value;
  }
}
```

Comparing the imperative version of `find` with the `filter` shown above, the only differences come down to `*` and `yield`.

1. `filter` is a generator (`function*`) that uses yields to return each `value` for which `f(value)` is true, and continues iterating until the input is fully consumed.
2. `find` is a ordinary function that uses `return` to return the first value for which `f(value)` is true, immediately exiting both the loop and the function.

Unlike lazy `filters`, `Array.prototype.filter` does not support lazy evaluation—it traverses the entire array and returns a new array containing all elements that evaluate to true. In contrast, a lazy version of `filter` produces an iterator that is only consumed as much as the consumer demands. If we call `next()` only once on such a lazy `filter`, its behavior and efficiency are effectively the same as `find`, because a single `yield` in that case behaves just like a `return`.

Now, here are three implementations of `find` written in a functional style:

##### [Code 3-43] A First Functional Implementation of `find`

```typescript
function find<A>(f: (a: A) => boolean, iterable: Iterable<A>): A | undefined {
  return filter(f, iterable).next().value;
  // Alternatively:
  // const [head] = filter(f, iterable);
  // return head;
}

// [const result: number | undefined]
const result = find(a => a > 2, [1, 2, 3, 4]);
console.log(result);  
// 3

const isOdd = (a: number) => a % 2 === 1;

const result2 = find(isOdd, [2, 4, 6]); // [const result2: number | undefined]
console.log(result2);
// undefined
```

In this first functional implementation, we use `filter` to prepare a lazy sequence of elements that satisfy the condition. Then, by calling `next()` only once on the returned iterator, we immediately retrieve the first matching element—at which point both the loop inside `filter` and the function itself terminate.

Alternatively, as shown in the commented example, we can use destructuring—`[head] =`—to extract the first element. Since the `filter` function supports lazy evaluation, this destructuring triggers only a single call to `next()` on the underlying iterator. As a result, it behaves just as efficiently as the imperative version of find shown in [Code 3-41].

##### [Code 3-44] A Second Functional Implementation of `find`

```typescript
const head = <A>(
  iterable: Iterable<A>
): A | undefined => iterable[Symbol.iterator]().next().value;
// Or: const head = <A>([a]: Iterable<A>): A | undefined => a;

const find = <A>(
  f: (a: A) => boolean, 
  iterable: Iterable<A>
): A | undefined => head(filter(f, iterable));

// [const result: number | undefined]
const result = find(a => a > 2, [1, 2, 3, 4]);
console.log(result);
// 3

const isOdd = (a: number) => a % 2 === 1;

const result2 = find(isOdd, [2, 4, 6]); // [const result2: number | undefined]
console.log(result2);
// undefined
```

In this second approach, we define a helper function called `head`, which returns the first element of a given iterable. The `find` function uses `filter` to lazily `filter` the input, then delegates to `head` to retrieve the first matching element. This method is similar to the first one, but improves modularity by separating concerns—`head` encapsulates the logic for extracting the first item. By defining `head` as a standalone function, we make the code more reusable and clarify the distinct roles of each function.

##### [Code 3-45] Revisiting `FxIterable`

```typescript
class FxIterable<A> {
  constructor(private iterable: Iterable<A>) {}

  // ... omitted ...

  filter(f: (a: A) => boolean): FxIterable<A> {
    return fx(filter(f, this));
  }

  to<R>(converter: (iterable: Iterable<A>) => R): R {
    return converter(this.iterable);
  }
}
```

##### [Code 3-46] A Third Functional Implementation of `find` using `FxIterable`

```typescript
const find = <A>(f: (a: A) => boolean, iterable: Iterable<A>): A | undefined => 
  fx(iterable)
    .filter(f)
    .to(head);

// [const result: number | undefined]
const result = find(a => a > 2, [1, 2, 3, 4]);
console.log(result);
// 3

const isOdd = (a: number) => a % 2 === 1;

const result2 = find(isOdd, [2, 4, 6]); // [const result2: number | undefined]
console.log(result2);
// undefined
```

This third approach uses the `FxIterable` class to implement find in a fluent, chainable style. We create an instance using the `fx` function, apply the `filter` method to prepare the sequence, and finally pass the `head` function to the `to` method to return the first matching element.

All three functional versions of `find` provide the same efficiency as the imperative approach in [Code 3-41], but with more concise and readable code. Compared to the imperative version, each of these functional implementations gives us a strong sense of confidence—they are so declarative and straightforward that we almost don’t need to test them to trust they work correctly.

At the beginning of Chapter 3, we made the following observation:

> - Ultimately, we can create an iterator in three ways, each fully interchangeable 1:1:1:
>  1. **Imperative** (IP) - Generators producing an iterator
>  2. **Object-oriented** (OOP) - Implementing an iterator class manually
>  3. **Functional** (FP) - Composing list processing functions to build an iterator

And near the end of chapter 1.2:

> We’ll try coding these iterators in an object-oriented style, imperative style, and functional style, exploring how they are 1:1:1 replacements.

We’ve demonstrated that higher-order functions like `find` can be built purely by combining list processing functions rather than imperative code, and that the functional approach is just as efficient. Indeed, using a functional approach to build `find` is highly convenient.

And code from each paradigm can fully replace each other or be mixed. A multiparadigm language user can, even in a single function, choose or combine the best-suited paradigm for the situation.

### Safe Composition in TypeScript: ? ?? !

Returning to our earlier example of using the `find` function and a `Maybe` type in Haskell to safely handle exceptional cases, here’s how TypeScript addresses such scenarios:

##### [Code 3-47] What Is Safe Composition? `? ?? !`

```typescript
const desserts = [
  { name: 'Chocolate', price: 5000 },
  { name: 'Latte', price: 3500 },
  { name: 'Coffee', price: 3000 }
];

// (1) Using the optional chaining operator (?.) for safe access to the `name` property
const dessert = find(({ price }) => price < 2000, desserts);
console.log(dessert?.name ?? 'T^T');
// T^T

// (2) Using the non-null assertion operator (!) to inform the language that we always expect to find something
const dessert2 = find(({ price }) => price < Infinity, desserts)!;
console.log(dessert2.name);
// Chocolate
```

In situations like these, TypeScript can use the optional chaining operator `?.` to enable safe composition, and conversely, use the non-null assertion operator `!` to explicitly propagate an error if the value doesn’t exist.

When you use method (1), **optional chaining**, if the actual value is missing, it will be treated as `undefined` without causing a runtime error. In contrast, method (2), **non-null assertion**, outright assumes the value exists, so if the value is in fact `null` or `undefined`, a runtime error may occur. Does that mean method (2) should be avoided? Or is it simply a trick to allow the code to compile?

Method (2) represents the developer telling the language, “I’ve designed this logic so that the value must exist.” In other words, “Here, `null` or `undefined` should never appear; if it does, it indicates our design is incorrect, and a runtime error should occur.” If such an error happens, the developer’s task isn’t to remove the `!`, but to investigate why the value couldn’t be found at runtime and fix the root cause (e.g. an issue with the API, a mistake in how data is stored in the database, or some scenario where the DOM element doesn’t exist).

TypeScript supports these operators alongside `try...catch` for safe composition, error propagation, and precise error handling. Additionally, the IDE can use the type system to suggest whether you should safely access a value via optional chaining, or whether this situation truly calls for a non-null assertion. By using these tools properly, you can detect potential runtime errors at the code-writing stage and clearly indicate whether you want safe composition or an explicit exception in the event of `null` or `undefined`.

#### 1. Accessing the `name` Property Safely with the Optional Chaining Operator (`?.`)

In this code, if the `dessert` object doesn’t exist (for example, if the `find` function returns `undefined`), it’s accessed safely, and `'T^T'` is printed when `dessert` doesn’t exist. This is done by using the optional chaining operator (`?.`) and the nullish coalescing operator (`??`) to safely retrieve values and provide a default.

1. If `dessert` is `undefined`, `dessert?.name` returns `undefined`. Otherwise, it returns `dessert.name`.
2. Finally, if `dessert?.name` is `undefined`, it returns `'T^T'`; otherwise, it returns the value of `dessert?.name`.

Code like `dessert?.name` acknowledges the possibility that `dessert` might not be found and indicates that returning `'T^T'` is the intended behavior if it’s `undefined`.

#### 2. Communicating Intent That We Will Always Find Something via the Non-Null Assertion Operator (`!`)

In the case of `dessert2.name`, if there’s any possibility that `dessert2` is missing, it contradicts the developer’s assumption that no such scenario should arise in this program. As a result, the language is told that if this actually happens, the error must not be suppressed but rather be propagated. In other words, the absence of `dessert2` is considered an error, and we detect it using the non-null assertion operator (`!`).

### every

Let’s now implement the `every` function. The `every` function should return `true` if the given function `f` returns `true` for all elements, or `false` otherwise.

First, here is the function signature of `every`. The comment shows the signature of Haskell’s `all` function, which has the same behavior:

##### [Code 3-48] `every` Function Signature

```typescript
// all :: (a -> Bool) -> [a] -> Bool
function every<A>(f: (a: A) => boolean, iterable: Iterable<A>): boolean {}
```

This time, instead of using imperative code, we’ll tackle the problem from a functional and list-processing perspective. In functional programming, we often think in terms of transforming a list step by step to derive a final result.

There are many possible methods, but here we’ll use the following strategy:
- Convert all elements of the list into `boolean` values, and then
- Combine all those `boolean` values with the logical AND operator (`&&`) to easily obtain the desired result.

##### [Code 3-49] Strategy for Implementing `every`

```typescript
// 1. [1, 3, 5]
// 2. [isOdd(1), isOdd(3), isOdd(5)]
// 3. (true && true && true)
```

There are various ways to implement `every`, but the approach suggested here is appealing because it can be applied in virtually any language. This method does not depend on language-specific or data-structure-specific features or syntax. Instead, it simply uses the logical AND operator (`&&`) supported by most languages. This allows us to implement the `every` function in concise, easily understandable code without being tied to a particular language.

Now let’s convert the above plan into code. In [Code 3-50], you can see that the plan from [Code 3-49] has indeed been directly transferred into the implementation.

##### [Code 3-50] Implementing `every`

```typescript
function every<A>(f: (a: A) => boolean, iterable: Iterable<A>): boolean {
  return fx(iterable)
    .map(f)
    .reduce((a, b) => a && b, true); // [a: boolean], [b: boolean]
}

console.log(every(isOdd, [1, 3, 5]));
// true
console.log(every(isOdd, [1, 2, 5]));
// false
```

The `every` function is created by chaining together `map(f)` and `reduce((a, b) => a && b, true)`.

1. We directly pass the function `f` received by `every` to the first `map`.
2. We then provide `(a && b)` as the accumulator function to `reduce`, producing the same effect as `(true && true && true)`.

Typically, when using `reduce`, we supply an accumulator function that adds (`+`), subtracts (`-`), or merges objects (`{...a, ...b}`) or arrays (`[...a, ...b]`), but in this scenario we are using the logical AND operator (`&&`) to accumulate the values. This is useful to check whether all elements satisfy a certain condition. In essence, `reduce` can be used to aggregate all elements with any operation, just like adding or subtracting.

Moreover, you might wonder why we are not implementing it directly in one pass with something like `(a && f(b))` in a single `reduce` call, and instead are splitting the logic into `map` and `reduce`. However, using `f(b)` in a single `reduce` and splitting it into `map` and `reduce` both have the same time complexity.

For example, `fx(list).reduce((a, b) => a && f(b), true)` evaluates `f(b)` on each element during a single pass, taking O(n) time. Meanwhile, `fx(list).map(f).reduce((a, b) => a && b, true)` might look like “map then reduce,” but because of lazy iterators, each element is mapped immediately before it’s consumed by `reduce`, resulting in just one pass of O(n) as well.

As another related case, if we were using a normal array rather than a lazy iterator—like `array.map(f).reduce(...)`—the array would first be fully mapped (producing a new array), and then reduced, effectively traversing the array twice. However, each pass is still O(n), so the overall complexity remains O(n). Even then, using a lazy iterator is more memory efficient since it does not require creating the intermediate array in memory.

In functional programming, composing functions in this manner increases simplicity and readability, and it can prove advantageous in asynchronous programming as well. Hence this approach is recommended.

### some

We can implement the `some` function in a similar way. The `some` function should return `true` if the given function `f` returns `true` for at least one element, or `false` if the function returns `false` for all elements.

Here is the function signature of `some`. The comment shows the signature of Haskell’s `any` function, which has the same behavior:

##### [Code 3-51] `some` Function Signature

```typescript
// any :: (a -> Bool) -> [a] -> Bool
function some<A>(f: (a: A) => boolean, iterable: Iterable<A>): boolean {}
```

We’ll use the same plan as with `every`. After converting all values to `boolean`, we combine those `boolean` values with the OR operator (`||`) to produce the desired outcome. Let’s express this in code.

##### [Code 3-52] Strategy for Implementing `some`

1. `[2, 3, 4]`
2. `[isOdd(2), isOdd(3), isOdd(4)]`
3. `(false || true || false)`

As mentioned earlier, there are many ways to implement `some` or `every`, and there could be more concise approaches as well. For example, you could check the truth value, find the `index` of a value that matches the condition and compare it with `-1`, or create an array with a single element and check if `length` is `0`. However, these methods retain a somewhat imperative feel even when using higher-order functions. They also tend to depend on language syntax or standard libraries, and code like `length === 0` is more imperative than declarative, specifically detailing 'how' it should operate rather than 'what' it does.

In contrast, methods like those in [Code 3-50] and [Code 3-53] are directly expressed in the full context of the code as functions that "check if all elements match this condition and then verify if they all satisfy (`true && true && false`)". Code that expresses 'what' is being done rather than 'how' to do it is not only easier to read and better captures the meaning, but is also easier to understand when revisited later.

##### [Code 3-53] Implementing `some`

```typescript
function some<A>(f: (a: A) => boolean, iterable: Iterable<A>): boolean {
  return fx(iterable)
    .map(f)
    .reduce((a, b) => a || b, false); // [a: boolean], [b: boolean]
}

console.log(some(isOdd, [2, 5, 6]));
// true
console.log(some(isOdd, [2, 4, 6]));
// false
```

Here, we used `(a || b)` as the accumulator in `reduce`, creating the same effect as `(false || true || false)`.

### Insert a “Break” Logic with Lazy Evaluation

In truth, neither the `some` nor the `every` function requires traversing all elements to produce a result. For `some`, if we encounter even one `true`, we can return `true` and stop further traversal. Conversely, for `every`, encountering just one `false` allows us to exit the loop immediately.

##### [Code 3-54] Increasing Efficiency in `some`

```typescript
function some<A>(f: (a: A) => boolean, iterable: Iterable<A>): boolean {
  return fx(iterable)
    .map(f)
    .filter(a => a)
    .take(1)
    .reduce((a, b) => a || b, false); // [a: boolean], [b: boolean]
}

console.log(some(isOdd, [2, 5, 6]));
// true
console.log(some(isOdd, [2, 4, 6]));
// false
```

We’ve improved on the earlier `some` function by adding `.filter(a => a).take(1)`:

1. This code now uses `.filter(a => a).take(1)` so that once it encounters a single `true`, it stops reading further elements and produces an iterator containing at most one element, which then goes to `reduce`.
2. If there isn’t a single `true`, the iterator passed to `reduce` is empty.
3. When there are no elements, `reduce` returns its initial value `false`; if there is a single element, we get `false || true` in one step, thus `true`.

This makes `some` as efficient as if we used an `if () break;` approach in a loop.

`every` can be optimized in a similar way.

##### [Code 3-55] Increasing Efficiency in `every`

```typescript
function every<A>(f: (a: A) => boolean, iterable: Iterable<A>): boolean {
  return fx(iterable)
    .map(f)
    .filter(a => !a)
    .take(1)
    .reduce((a, b) => a && b, true); // [a: boolean], [b: boolean]
}

console.log(every(isOdd, [1, 3, 5]));
// true
console.log(every(isOdd, [1, 2, 5]));
// false
```

We improved on the previous `every` by adding `.filter(a => !a).take(1)`:

1. Now, `.filter(a => !a).take(1)` means if we see even one `false`, we stop reading further elements. Only an iterator with at most one element is passed to `reduce`.
2. If there’s no `false`, the iterator passed to `reduce` remains empty.
3. If there are no elements, `reduce` returns its initial value `true`; if one element is present, that element will be `false`, leading to `true && false` once, which returns `false`.

Thus, we’ve confirmed that functions like `every` and `some` can be composed from list-processing functions in a functional style rather than using imperative logic.

### Abstracting Shared Logic in `every` and `some` Functionally

Because functional programming treats lists, code, and functions as values, it’s extremely easy to factor out common logic. Our implementations of `every` and `some` so far are nearly identical in structure. Below is a functional programming solution for removing this duplication:

##### [Code 3-56] The `accumulateWith` Function

```typescript
function accumulateWith<A>(
  accumulator: (a: boolean, b: boolean) => boolean,
  acc: boolean,
  taking: (a: boolean) => boolean, 
  f: (a: A) => boolean, 
  iterable: Iterable<A>
): boolean {
  return fx(iterable)
    .map(f)
    .filter(taking)
    .take(1)
    .reduce(accumulator, acc);
}

function every<A>(f: (a: A) => boolean, iterable: Iterable<A>): boolean {
  return accumulateWith((a, b) => a && b, true, a => !a, f, iterable);
}

function some<A>(f: (a: A) => boolean, iterable: Iterable<A>): boolean {
  return accumulateWith((a, b) => a || b, false, a => a, f, iterable);
}

console.log(every(isOdd, [1, 3, 5]));
// true
console.log(every(isOdd, [1, 2, 5]));
// false

console.log(some(isOdd, [2, 5, 6]));
// true
console.log(some(isOdd, [2, 4, 6]));
// false
```

In [Code 3-56], we employ the `accumulateWith` function to factor out shared logic between `every` and `some`. It’s especially notable that we pass around the logic-holding code as a function. Because `every` and `some` already used calls like `fx(iterable).map(f).filter(a => !a).take(1).reduce((a, b) => a && b, true)`, we simply took those functional pieces and turned them into arguments, finishing the abstraction with minimal modification. The duplication was removed so smoothly that it hardly needs explanation. In this way, functional programming is well-suited to refactoring and offers excellent maintainability.

### Adding with `concat`

The array method `concat` is used to merge multiple arrays into one. For instance, `arr.concat(arr2)` returns a new array that combines `arr` and `arr2`, leaving the original array unmodified. However, because `concat` immediately evaluates and merges all elements into a new array, memory usage can grow significantly when merging very large arrays.

On the other hand, by implementing `concat` with a generator, you can process elements as needed through lazy evaluation, which may offer improved memory efficiency and performance.

#### Implementing `concat` with Generators

Using generators, you can concisely merge arrays or iterables as shown below:

##### [Code 3-57] `concat`

```typescript
function* concat<T>(...iterables: Iterable<T>[]): IterableIterator<T> {
  for (const iterable of iterables) yield* iterable;
}

const arr = [1, 2, 3, 4];
const iter = concat(arr, [5]);
console.log([...iter]);
// [1, 2, 3, 4, 5]
```

This `concat` function takes multiple iterables as arguments and sequentially yields each element. Rather than merging entire arrays at once, it processes elements one by one when needed. In other words, it doesn’t actually combine arrays but simply continues iteration. Let’s look at the difference between the array method `concat` and the generator-based `concat`.

#### Differences Between Array `concat` and Generator `concat`

The following code compares array `concat` with generator `concat`.

##### [Code 3-58] Comparing `concat`

```typescript
const arr = [1, 2, 3, 4, 5];

// Example using array concat
const arr2 = arr.concat([6, 7, 8, 9, 10]);
console.log(arr2); // [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
let acc = 0;
for (const a of take(7, arr2)) {
  acc += a;
}
console.log(acc); // 28

// Example using generator concat
const iter = concat(arr, [6, 7, 8, 9, 10]);
console.log(iter); // concat {<suspended>} (nothing happens yet)
let acc2 = 0;
for (const a of take(7, iter)) {
  acc2 += a;
}
console.log(acc2); // 28
```

In this example, `arr.concat([6, 7, 8, 9, 10])` creates a new array `[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`. In contrast, the generator-based `concat` does not create a new array; rather, it yields combined elements one by one.

When using the array method `concat`, memory usage increases when large arrays are copied. This happens because the newly created array must generate a large index table to hold all elements and reassign all those slots. In contrast, the generator-based `concat` does not copy values; it generates values only when needed, operating more efficiently. In [Code 3-58], we only need to compute the value for `acc`, yet `arr2` is still created as a new array. The generator-based `concat` does not create that new array but carries out only the needed operations to compute `acc2`.

#### Thinking About Using `concat` Instead of `push`

`push` is a method that adds elements to the end of an array, modifying the original array. With generator `concat`, you can achieve the same effect without altering the original array, while also taking advantage of lazy evaluation to process data more efficiently.
##### [Code 3-59] Using `push`

```typescript
const arr = [1, 2, 3, 4, 5];

// Example of adding elements with push and then summing
arr.push(6, 7);
let acc1 = 0;
for (const a of arr) {
  acc1 += a;
}
console.log(acc1); // 28
console.log(arr); // [1, 2, 3, 4, 5, 6, 7]

// Remove the elements added with push (restore the original array)
arr.pop();
arr.pop();

// Example of adding elements again with push and then summing
arr.push(8, 9);
let acc2 = 0;
for (const a of arr) {
  acc2 += a;
}
console.log(acc2); // 32
console.log(arr); // [1, 2, 3, 4, 5, 8, 9]

// Remove the elements added with push (restore the original array)
arr.pop();
arr.pop();
```

##### [Code 3-59a] Using `concat`

```typescript
const arr = [1, 2, 3, 4, 5];

// Example of creating an iterator with generator concat and then summing
const iter1 = concat(arr, [6, 7]);
let acc3 = 0;
for (const a of iter1) {
  acc3 += a;
}
console.log(acc3); // 28
console.log(arr); // [1, 2, 3, 4, 5]

// Example of adding different elements with generator concat and then summing
const iter2 = concat(arr, [8, 9]);
let acc4 = 0;
for (const a of iter2) {
  acc4 += a;
}
console.log(acc4); // 32
console.log(arr); // [1, 2, 3, 4, 5]
```

Generator-based `concat` does not modify the original array and only generates elements when needed, which is particularly useful if you need to reuse the original array multiple times. In contrast, the array method `concat` allocates a new array in memory. As arrays grow larger, memory usage can increase. Since generator-based `concat` doesn’t allocate a new array, it minimizes memory usage by generating values incrementally.

Hence, generator `concat` can be a great option for memory efficiency and flexibility. Of course, you do not need to replace `push` with generator `concat` in every situation—there are cases where `push` is more suitable. It’s important to choose the right method for your needs.

#### Thinking About Using `concat` Instead of `unshift`

`unshift` is a method that adds new elements to the front of an array, modifying the original array. In doing so, it may need to shift all existing elements one index over, which can be costly for large arrays. By using generator-based `concat`, you can add elements at the front without modifying the original array, processing data more efficiently through lazy evaluation.

##### [Code 3-60] Example of Adding Elements with `unshift` and Joining into a String

```typescript
const arr = ['2', '3', '4', '5'];
arr.unshift('1');
console.log(arr); // ['1', '2', '3', '4', '5']
let result1 = '';
for (const str of arr) {
  result1 += str;
}
console.log(result1); // '12345'
```

When you use `unshift`, adding an item to the front of the array may require shifting all existing items one step to the right, which grows more expensive as the array size increases. For instance, if there are 100 elements in the array, adding an element at the front means shifting all 100 elements, increasing the time complexity for large arrays.

##### [Code 3-60a] Using Generator `concat` to Add Elements at the Front and Then Join into a String

```typescript
const arr = ['2', '3', '4', '5'];
const iter = concat(['1'], arr);
console.log(arr); // ['2', '3', '4', '5']
let result2 = '';
for (const str of iter) {
  result2 += str;
}
console.log(result2); // '12345'
```

In contrast, generator `concat` does not require shifting indices. It simply generates the newly added elements in front as needed, which can be more efficient in terms of both memory and performance.

#### Using `take` Together with `concat`

If you opt for `concat` instead of `unshift` and only fetch as many elements as needed using `take`, you can work with just the required items without manipulating the entire array.

##### [Code 3-61] Combining `take` and `concat`

```typescript
const arr1 = [1, 2, 3, 4, 5];
const arr2 = [6, 7, 8, 9, 10];
const iter = take(3, concat(arr1, arr2));
console.log([...iter]); // [1, 2, 3]
```

This method works efficiently by processing only the required items. In this scenario, it never even iterates over `arr2`, making it effectively the same as not calling `concat` on `arr2` at all.

#### Using `some` Together with `concat`

If you replace `unshift` with `concat` and use `some` to find an element that satisfies a condition, the generator approach can be more efficient by only generating and processing what is necessary. Since the `some` function stops as soon as it finds a matching element, no unnecessary computations occur.

##### [Code 3-62] Using `some` with `concat`

```typescript
const arr = [3, 4, 5];
console.log(some(n => n < 3, arr));
// false

const iter = concat([1, 2], arr);
console.log(some(n => n < 3, iter));
// true
```

We’ve now seen several examples of how to use generator-based `concat` with lazy evaluation. In particular, this approach demonstrates how to work with a list through lazy processing instead of modifying the values directly. This can enable efficient, flexible processing and can spark plenty of new ideas.

#### Code:Object:Function = Generator:Iterator:LISP = IP:OOP:FP

In Chapter 3, we explored a wide range of paradigms and techniques proposed by LISP and various modern languages, along with inspiration from Haskell, practical execution and application of lazy evaluation, and TypeScript’s handling of safe composition and error handling. We also looked at how to implement functional code and refactor imperative code using list-processing concepts and ways of replacing value mutation with new ideas, thereby seeing how different paradigms interconnect and complement each other.

In a multiparadigm language, it’s possible to mix different paradigms in a single function. Selecting or combining the right paradigms for the context can lead to better solutions.

---

## Navigation

- [Table of Contents](README.md)
- [Prev](3.3-Taking-a-Closer-Look-at-Lazy-Evaluation.md)
- [Next](3.5-Summary.md)